# Estudos_DS_em_T
Programa pessoal de estudos em Data Science e outras áreas correlatas, como BI, Marketing Analytics, Cloud, etc.

O Roadmap de estudos é baseado em trilhas de conteúdo da Alura, bem como artigos e vídeos online. Por fim, pedi para que o ChatGPT me ajudasse a organizar os tópicos em Macros, com Objetivos-Chave.

Segue o Roadmap detalhado:

# Roadmap de estudos em DataScience

## Eixo Data Science

### **Macro 0: Ferramentas Fundamentais para Tecnologia**

**Objetivo:** Estabelecer uma base sólida no uso de ferramentas essenciais para desenvolvimento e colaboração em projetos tecnológicos, incluindo terminais de comando, controle de versão e ferramentas de documentação e automação.

### **Objetivos Chave**

1. **Git e GitHub: Controle de Versão e Colaboração**
    - Aprender os fundamentos de Git para controle de versão, incluindo operações básicas como commit, push e pull.
    - Explorar GitHub para compartilhamento de código e colaboração em projetos, permitindo o gerenciamento eficiente de versões.
2. **Uso de Terminais de Comando (Linux e Windows)**
    - Familiarizar-se com o terminal Linux e o prompt de comando do Windows, compreendendo comandos básicos de navegação, criação de arquivos e execução de scripts.
    - Entender o uso de máquinas virtuais e o ambiente de linha de comando para automação de tarefas.
3. **Expressões Regulares (Regex)**
    - Aprender a utilizar expressões regulares para busca, validação e substituição de dados em grandes volumes de texto.
    - Praticar regex para manipulação de dados, uma habilidade fundamental para desenvolvedores e cientistas de dados.
4. **Configuração de Ferramentas de Desenvolvimento (VSCode, Nginx e Swagger)**
    - Conhecer os principais recursos do Visual Studio Code para aumentar a produtividade no desenvolvimento.
    - Aprender a configurar e utilizar Nginx para servidores web e proxies reversos, e Swagger para documentação de APIs.
5. **Inteligência Artificial para Produtividade em Programação**
    - Explorar ferramentas de IA como ChatGPT e GitHub Copilot para suporte em programação, incluindo geração de código, sugestões e debugging.
    - Otimizar a qualidade do código com assistência de IA para melhorar a produtividade e eficiência no desenvolvimento.
6. **Padronização de APIs**
    - Compreender os padrões de API e o protocolo HTTP para criação de sistemas integrados.
    - Aprender a modelar APIs de forma consistente e estruturada, facilitando a comunicação entre serviços.

### **Marco 1: Fundamentos de Programação e Exploração de Dados**

- Duração: 1 a 2 meses

Este marco se concentra em criar uma base sólida de conhecimentos fundamentais em programação e análise de dados para ciência de dados, utilizando Python e ferramentas associadas.

**Objetivos Chave**

1. **Introdução à Programação com Python**
    - Aprender os principais elementos da linguagem, incluindo estruturas de dados (listas, dicionários) e controle de fluxo (loops e condicionais).
    - Desenvolver lógica de programação para resolver problemas básicos e manipular dados de forma eficiente.
2. **Ambientes de Programação**
    - Familiarizar-se com ambientes de trabalho para ciência de dados, como Jupyter Notebook e Google Colab.
    - Executar e visualizar código em blocos, aproveitando o ambiente interativo para documentar e organizar a análise.
3. **Manipulação de Dados com Bibliotecas Básicas**
    - Usar a biblioteca **Pandas** para manipulação de DataFrames, leitura de arquivos CSV e tratamento de dados ausentes.
    - Utilizar **NumPy** para operações matemáticas e manipulação de arrays, facilitando cálculos com grandes conjuntos de dados.
4. **Estatística Básica para Análise de Dados**
    - Compreender medidas de tendência central (média, mediana, moda) e dispersão (variância, desvio padrão).
    - Estudar distribuições de dados (normal e binomial) para descrever e interpretar padrões de dados.
5. **Visualização de Dados com Matplotlib e Seaborn**
    - Criar gráficos e visualizações, incluindo histogramas e boxplots, para interpretar e comunicar insights de dados visualmente.
    - Explorar os gráficos como uma ferramenta inicial para explorar a distribuição e a estrutura dos dados.

### **Marco 2: Análise Exploratória e Feature Engineering**

- Duração: 1 a 1,5 meses

Neste marco, o foco é aprofundar-se em análise exploratória para entender melhor os dados e desenvolver habilidades de criação e manipulação de features, facilitando a modelagem posterior. A preparação de dados e a identificação de padrões são as bases para análises mais avançadas em Machine Learning.

**Objetivos Chave**

1. **Exploração de Dados (EDA)**
    - Utilizar funções básicas do Pandas como `describe()`, `info()`, e `value_counts()` para obter uma visão geral dos dados e suas características.
    - Identificar variáveis categóricas e numéricas, explorando a distribuição dos dados para avaliar a necessidade de transformações ou ajustes.
2. **Feature Engineering**
    - Criar novas variáveis (features) a partir dos dados brutos, adicionando valor à análise e aumentando o potencial dos modelos.
    - Aplicar técnicas de **normalização** e **padronização** para assegurar que as variáveis estejam em uma escala adequada para algoritmos de Machine Learning.
    - Realizar transformações nos dados, como conversões de variáveis categóricas e criação de variáveis derivadas, para enriquecer a análise.
3. **Tratamento de Dados**
    - Limpar e tratar valores ausentes, outliers e inconsistências, garantindo que o conjunto de dados esteja pronto para a modelagem.
    - Implementar métodos de **codificação** para variáveis categóricas, como **One-Hot Encoding** e **Label Encoding**, para preparar as variáveis para o treinamento de modelos.

### **Marco 3: Fundamentos de Estatística e Regressão**

Este marco aprofunda-se em conceitos de estatística descritiva e inferencial, preparando o terreno para as primeiras técnicas de modelagem preditiva por meio de regressão. Esses conceitos são fundamentais para entender as relações entre variáveis e desenvolver modelos baseados em dados.

**Objetivos Chave**

1. **Estatística Avançada**
    - Compreender os fundamentos da **inferência estatística**, incluindo testes de hipóteses e construção de intervalos de confiança, para avaliar a validade de insights e conclusões extraídas dos dados.
    - Explorar conceitos básicos de **séries temporais**, analisando padrões e tendências ao longo do tempo para entender e prever o comportamento dos dados em intervalos específicos.
2. **Regressão Linear**
    - Estudar a **relação entre variáveis dependentes e independentes** e entender como essas interações podem ser quantificadas.
    - Criar e interpretar **modelos de regressão linear simples e múltipla**, aplicando essas técnicas para prever resultados e analisar o impacto de múltiplos fatores em uma variável-alvo.
3. **Prática com Projetos de Regressão**
    - Desenvolver projetos práticos que envolvem a construção de modelos de regressão linear, aplicando dados reais para prever resultados e validar o modelo.
    - Utilizar métricas de avaliação para interpretar a eficácia dos modelos de regressão e identificar possíveis melhorias.

Esses objetivos são fundamentais para consolidar a análise estatística e a modelagem preditiva, tornando-se uma base essencial para algoritmos mais complexos em Machine Learning.

### **Marco 4: Fundamentos de Machine Learning Supervisionado**

**Resumo:** Esta fase foca no aprendizado dos fundamentos do machine learning supervisionado, proporcionando o entendimento dos algoritmos clássicos de regressão e classificação e introduzindo métricas de avaliação para medir a eficácia dos modelos.

**Objetivos Chave:**

1. **Conceitos de Machine Learning Supervisionado**
    - Compreender os princípios de aprendizado supervisionado, diferenciando entre problemas de classificação e regressão.
    - Familiarizar-se com o uso do **Scikit-learn** para construir e treinar modelos de machine learning.
2. **Algoritmos Clássicos de Machine Learning**
    - Aprender sobre **Regressão Linear e Logística** e suas aplicações práticas.
    - Explorar algoritmos populares de classificação, como **K-Nearest Neighbors (KNN)**, **Decision Trees** e **Random Forest**.
3. **Avaliação de Modelos**
    - Compreender métricas de avaliação, incluindo **accuracy, precision, recall** e **F1-Score** para avaliar o desempenho dos modelos.
    - Aplicar estratégias de divisão de dados, como treino e teste, e validação cruzada para assegurar a robustez do modelo.
4. **Prática com Projetos**
    - Implementar modelos supervisionados em problemas práticos de classificação e regressão, interpretando os resultados para insights aplicáveis.

---

### **Marco 5: Machine Learning Não Supervisionado**

**Resumo:** Esta fase foca em técnicas de aprendizado não supervisionado para identificação de padrões e agrupamentos em dados, com ênfase em algoritmos de clustering e redução de dimensionalidade.

**Objetivos Chave:**

1. **Clustering (Agrupamento de Dados)**
    - Aprender sobre algoritmos de agrupamento, como **K-Means**, **DBSCAN** e **Mean Shift**.
    - Aplicar métricas de avaliação de clusters, como **Silhouette Score** e **Davies-Bouldin**, para medir a qualidade dos agrupamentos.
2. **Redução de Dimensionalidade**
    - Introduzir o **PCA (Principal Component Analysis)** para simplificar conjuntos de dados complexos sem perder informação relevante.
3. **Prática com Projetos de Clustering**
    - Desenvolver projetos que envolvem clustering, utilizando dados não rotulados para identificar padrões ocultos e estruturas dentro dos dados.

---

### **Marco 6: Deep Learning e Redes Neurais**

**Resumo:** Este marco é uma introdução ao aprendizado profundo (Deep Learning) e redes neurais, explorando o funcionamento das redes neurais artificiais e técnicas para reconhecimento de imagens.

**Objetivos Chave:**

1. **Fundamentos de Redes Neurais**
    - Compreender a estrutura e o funcionamento das redes neurais artificiais (ANN), incluindo conceitos de funções de ativação, pesos e vieses.
2. **Frameworks de Deep Learning**
    - Aprender a construir modelos de deep learning com **TensorFlow** e **Keras**, aplicando técnicas de otimização para melhorar a precisão do modelo.
3. **Modelos de Classificação de Imagens**
    - Implementar **Redes Neurais Convolucionais (CNNs)** para classificação de imagens, explorando seu papel em tarefas de reconhecimento de padrões visuais.
4. **Prática com Projetos de Deep Learning**
    - Desenvolver um projeto prático de reconhecimento de imagens utilizando CNNs, interpretando o desempenho do modelo e ajustando conforme necessário.

---

### **Marco 7: Avaliação e Deploy de Modelos**

**Resumo:** Neste marco, o foco está em aprimorar os modelos de machine learning por meio de técnicas de otimização e implementar os modelos em ambiente de produção.

**Objetivos Chave:**

1. **Avaliação e Otimização de Modelos**
    - Identificar e corrigir problemas de **overfitting** e **underfitting** nos modelos.
    - Aplicar **Hyperparameter Tuning** com ferramentas como **GridSearchCV** e **RandomizedSearchCV** para melhorar a precisão e eficiência dos modelos.
2. **Deploy de Modelos**
    - Aprender a salvar modelos treinados com **Pickle** ou **Joblib**.
    - Implementar o deploy de modelos em APIs web usando **Flask** ou **FastAPI** para permitir que o modelo seja utilizado em tempo real.
3. **Prática com Pipeline Completo**
    - Criar um pipeline de machine learning completo, desde o treinamento do modelo até a implementação e teste em ambiente de produção.

---

### **Marco 8: Aplicação e Especialização**

**Resumo:** Este último marco consolida o aprendizado com projetos práticos e competições, aplicando o conhecimento em casos de uso avançados e específicos de ciência de dados.

**Objetivos Chave:**

1. **Projetos Práticos**
    - Participar de competições no **Kaggle** para resolver problemas de dados reais e aprimorar habilidades de análise e modelagem.
    - Desenvolver projetos que envolvem previsão de **séries temporais**, **processamento de linguagem natural (NLP)**, e **visão computacional**.
2. **Estudo de Casos Reais**
    - Aplicar habilidades de ciência de dados para resolver problemas de marketing e negócios, como **segmentação de clientes**, **previsão de churn**, e **otimização de campanhas**.

Esses marcos finais visam consolidar e especializar o conhecimento em ciência de dados, permitindo o desenvolvimento de soluções complexas e aplicáveis ao mundo real.

### Tabela do Roadmap:

| Roadmap de DataScience | Compreender os padrões de API e o protocolo HTTP | **1. Fundamentos de Programação e Exploração de Dados** | **2. Análise Exploratória e Feature Engineering** | **3. Fundamentos de Estatística e Regressão** | **4. Fundamentos de Machine Learning Supervisionado** | **5. Machine Learning Não Supervisionado** | **6. Deep Learning e Redes Neurais** | **7. Avaliação e Deploy de Modelos** | **8. Aplicação e Especialização** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **Duração Estimada** | 2 semanas | 1-2 meses | 1-1,5 meses | 1-2 meses | 2-3 meses | 1-2 meses | 2-3 meses | 1-1,5 meses | Contínuo |
| **Objetivo 1** | Dominar funções básicas do Git e GitHub | Aprender conceitos iniciais da programação com Python | Aprender Exploração de Dados (EDA) com Pandas | Aprender sobre inferência estatística e séries temporais | Aprender sobre aprendizado supervisionado e Scikit-learn | Conhecer técnicas e ferramentas para clustering | Aprender sobre os fundamentos de Redes Neurais | Ser capaz de avaliar e otimizar modelos | Participar de competições no Kaggle |
| **Objetivo 2** | Familiarizar com o prompt de comandos do Windows | Conhecer o Jupyter Notebooks e o Google Colab | Aprender a normalizar, padronizar e transformar dados | Ser capaz de fazer Regressão Linear | Conhecer os principais algoritmos clássicos de Machine Learning | Aprender sobre Redução de Dimensionalidade | Ser capaz de trabalhar com os principais frameworks de Deep Learning | Aprender Deploy de Modelos utilizando APIs | Participar de projetos open source colaborativos |
| **Objetivo 3** | Aprender a utilizar Regex | Conhecer Bibliotecas Pandas e Numpy | Ser capaz de criar novas variáveis a partir de dados brutos | Projeto com regressão linear para predição de resultados | Ser capaz de fazer avaliação de modelos de Machine Learning | Projeto de Clustering para identificação de padrões ocultos | Implementar modelos de Classificação de Imagens | Projeto de pipeline completo do treinamento ao deploy de modelo | Fazer estudos de casos reais em marketing |
| **Objetivo 4** | Conhecer principais recursos e configurações de VSCode, Nginx e Swagger | Aprender estatística básica (média, mediana e distribuições) | Aprender a limpar dados trabalha com variáveis categóricas |  | Projeto de implementação de modelo |  | Projeto de implementação de rede neural para classificação de imagens |  |  |
| **Objetivo 5** | Compreender os padrões de API e o protocolo HTTP | Conhecer Matplotlib e Seaborn | Projeto de análise exploratória e pré-processamento de dados |  |  |  |  |  |  |

## Eixo Business

Para o eixo de **Negócios**, com um foco adicional em temas específicos de marketing, vamos dividir o roadmap em etapas progressivas. Incluí algumas sugestões para expandir seu conhecimento em ferramentas e técnicas aplicáveis a marketing digital, analytics e automação, além de fundamentos essenciais para análise de dados orientada a negócios.

### **Marco 1: Fundamentos de Negócios e KPIs**

**Objetivo:** Entender o funcionamento dos negócios, a definição e o uso de KPIs, e como analisar métricas para apoiar decisões estratégicas.

- **Gestão de Processos de Negócios:**
    - **BPM (Business Process Management):** Métodos para mapear, analisar e otimizar processos empresariais.
    - **Definição de KPIs e OKRs:** Entender como construir e monitorar indicadores de desempenho alinhados aos objetivos de negócio.
- **Business Intelligence (BI):**
    - **Ferramentas de BI:** Introdução ao Power BI e Tableau para criação de dashboards e visualizações que auxiliam na tomada de decisão.
    - **ETL (Extração, Transformação e Carga):** Conhecer o processo ETL e sua importância na preparação de dados para análise.
- **Métricas de Negócios para Tomada de Decisão:**
    - Compreender e interpretar métricas de análise descritiva e inferencial, como média, desvio padrão e correlações.

---

### **Marco 2: Analytics e Análise de Marketing**

**Objetivo:** Desenvolver habilidades em análise de dados aplicados ao marketing digital, incluindo métricas específicas e ferramentas de análise.

- **Google Analytics e Analytics de Redes Sociais:**
    - **Google Analytics:** Monitoramento de tráfego, análise de comportamento do usuário, e funis de conversão.
    - **Social Media Analytics:** Utilizar ferramentas de monitoramento como Facebook Insights e Instagram Insights para entender métricas de engajamento e alcance.
- **Redes Sociais e Ferramentas de Anúncios:**
    - **Ferramentas de Anúncios (Facebook Ads, Google Ads):** Aprender a criar e monitorar campanhas, segmentar públicos e medir ROAS (Return on Ad Spend).
    - **Remarketing e Segmentação:** Técnicas de segmentação avançada e remarketing para campanhas mais eficazes.
- **SEO e Métricas de Search:**
    - **SEO (Search Engine Optimization):** Conceitos de SEO, palavras-chave, e estratégias para otimização de sites.
    - **SEO Analytics com Google Search Console:** Monitoramento de palavras-chave, impressões, e cliques para otimizar conteúdo.

---

### **Marco 3: Marketing Digital e Automações**

**Objetivo:** Implementar estratégias de automação e otimização em campanhas de marketing digital para aumentar a eficiência e a personalização.

- **Automação de Marketing:**
    - **Ferramentas de Automação (HubSpot, RD Station):** Configuração e monitoramento de automações de e-mail, nutrição de leads e campanhas de CRM.
    - **Análise e Segmentação de Leads:** Uso de pontuação de leads e segmentação para direcionar campanhas personalizadas.
- **Marketing de Conteúdo e Storytelling:**
    - **Criação e Distribuição de Conteúdo:** Desenvolvimento de conteúdo orientado a personas e uso de storytelling para engajamento.
    - **Email Marketing e Automação de Campanhas:** Configuração de campanhas de email marketing segmentadas e personalizadas.
- **Data-Driven Marketing e Ferramentas de Teste A/B:**
    - **A/B Testing e Otimização de Conversão (CRO):** Utilização de testes A/B e análise de funis de conversão para otimizar páginas e campanhas.
    - **Utilização de Ferramentas de Teste (Google Optimize, Optimizely):** Ferramentas para criar e monitorar experimentos que orientem a tomada de decisão baseada em dados.

---

### **Marco 4: Otimização e Estratégias Avançadas de Marketing**

**Objetivo:** Aplicar técnicas avançadas de marketing orientadas por dados para otimização de campanhas e personalização em escala.

- **Machine Learning Aplicado a Marketing:**
    - **Modelos de Previsão e Churn Prediction:** Utilização de algoritmos para prever comportamentos de clientes e identificar riscos de churn.
    - **Segmentação Avançada e Personalização:** Uso de clustering e análise preditiva para segmentar públicos com maior precisão.
- **Data-Driven Storytelling e Apresentação de Insights:**
    - **Apresentação de Dados para Executivos:** Técnicas de storytelling com dados para comunicar insights de maneira clara e convincente.
    - **Visualização de Dados com Power BI/Tableau:** Construção de dashboards avançados para monitoramento contínuo de campanhas e indicadores de marketing.

---

### **Marco 5: Fundamentos Financeiros para Negócios**

**Objetivo:** Compreender os princípios financeiros e desenvolver habilidades para análise e gestão de finanças em um contexto de negócios.

- **Contabilidade Básica e Demonstrações Financeiras:**
    - Introdução aos conceitos de contabilidade e análise de balanço patrimonial, DRE (Demonstração de Resultados) e fluxo de caixa.
    - Interpretação de relatórios financeiros para entender a saúde financeira da empresa.
- **Análise de Investimentos e Retorno:**
    - Cálculo de ROI, Payback e análise de viabilidade de projetos.
    - Introdução a indicadores de performance financeira, como margem de lucro, lucratividade e rentabilidade.
- **Orçamento e Planejamento Financeiro:**
    - Técnicas de planejamento e controle de orçamento, previsão de despesas e receitas.
    - Análise de variações e ajustes orçamentários para maximizar a eficiência de recursos.

---

### **Marco 6: Práticas de Negócios e Estratégias Empresariais**

**Objetivo:** Desenvolver habilidades para planejar, executar e otimizar práticas de negócios, incluindo análise estratégica e gestão de operações.

- **Gestão de Operações:**
    - Princípios de gestão operacional, com foco na otimização de processos e controle de qualidade.
    - Introdução ao Lean e Six Sigma para eficiência e eliminação de desperdícios.
- **Planejamento Estratégico:**
    - Desenvolvimento e implementação de estratégias empresariais com base em análise de mercado e concorrência.
    - Ferramentas estratégicas como Análise SWOT, Matriz BCG e Forças de Porter.
- **Gestão de Relacionamento com Clientes (CRM):**
    - Utilização de ferramentas de CRM para melhorar a experiência do cliente e otimizar interações.
    - Análise de métricas de satisfação, retenção e lifetime value dos clientes.

---

### **Marco 7: Metodologias Ágeis e Gestão de Projetos**

**Objetivo:** Aprender as práticas de metodologias ágeis e aplicar conceitos de gestão de projetos para melhorar a execução e adaptabilidade em ambientes dinâmicos.

- **Fundamentos de Agile e Scrum:**
    - Conceitos básicos de Agile, incluindo os valores e princípios do Manifesto Ágil.
    - Estrutura e cerimônias do Scrum (Daily Standup, Sprint Planning, Review, Retrospective) para gestão ágil de projetos.
- **Gestão de Projetos com Kanban e Lean:**
    - Uso do Kanban para visualização e gerenciamento de tarefas em fluxos contínuos.
    - Princípios Lean para otimizar processos e reduzir desperdícios em projetos.
- **Ferramentas de Gestão Ágil:**
    - Utilização de ferramentas como Jira, Trello e Asana para organização de tarefas, gestão de backlog e acompanhamento de sprints.
    - Métricas ágeis (velocity, lead time, cycle time) para avaliar o desempenho da equipe.

---

### **Marco 8: Compliance e Ética Corporativa**

**Objetivo:** Entender o papel do compliance e da ética nos negócios, com foco em regulamentos, políticas internas e práticas de governança.

- **Introdução ao Compliance Empresarial:**
    - Compreensão de normas e regulamentos que impactam os negócios, como LGPD (Lei Geral de Proteção de Dados) e outras legislações.
    - Políticas de conformidade e criação de código de conduta para assegurar a aderência a leis e regulamentos.
- **Gestão de Riscos e Controles Internos:**
    - Identificação e mitigação de riscos empresariais através de práticas de controle interno.
    - Avaliação de riscos operacionais, financeiros e de conformidade.
- **Ética Corporativa e Responsabilidade Social:**
    - Práticas éticas nos negócios, incluindo a relação com stakeholders e sustentabilidade.
    - Estratégias de responsabilidade social corporativa para fortalecer a imagem da empresa.

---

Esses novos marcos complementam o eixo de Negócios, proporcionando um entendimento abrangente de finanças, práticas estratégicas, metodologias ágeis e compliance, essenciais para uma visão completa e prática de gestão empresarial.

### Tabela do Roadmap:

| Roadmap de Business e Marketing | **1. Fundamentos de Negócios e KPIs** | **2. Analytics e Análise de Marketing** | **3. Marketing Digital e Automações** | **4. Otimização e Estratégias Avançadas de Marketing** | **Fundamentos Financeiros para Negócios** | **Práticas de Negócios e Estratégias Empresariais** | **Metodologias Ágeis e Gestão de Projetos** | **Compliance e Ética Corporativa** |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| **Duração Estimada** | 1-1,5 meses | 1-2 meses | 2-3 meses | 2-3 meses | 1,5-2 meses | 1,5-2 meses | 1-1,5 meses | 1-1,5 meses |
| **Objetivo 1** | Aprender a mapear, analisar e otimizar processos empresariais e construir indicadores | Dominar o Google Analytics e ferramentas de monitoramento de redes sociais | Configurar e monitorar ferramentas de automação e CRM e ser capaz de analisar e segmentar leads | Utilizar modelos de aprendizado para previsões de métricas e segmentações avançadas | Contabilidade Básica e Demonstrações Financeiras | Gestão de Operações | Fundamentos de Agile e Scrum | Introdução ao Compliance Empresarial |
| **Objetivo 2** | Dominar ferramentas de Business Intelligence: Power BI e Tableau | Aprender a criar e monitorar campanhas, segmentar públicos e medir ROAS | Dominar a criação de conteúdo orientado a personas | Ser capaz de fazer apresentação clara dos dados, através de Storytelling | Análise de Investimentos e Retorno | Planejamento Estratégico | Gestão de Projetos com Kanban e Lean | Gestão de Riscos e Controles Internos |
| **Objetivo 3** | Compreender e interpretar métricas de análises descritivas e inferenciais | Aprender a definir palavras-chave e a monitorar métricas para otimização de sites | Email Marketing e Automação de Campanhas | Dominar a visualização de Dados com Power BI e Tableau | Orçamento e Planejamento Financeiro | Gestão de Relacionamento com Clientes (CRM) | Ferramentas de Gestão Ágil | Ética Corporativa e Responsabilidade Social |
| **Objetivo 4** |  |  | Saber utilizar Testes A/B e ferramentas de testes |  |  |  |  |  |

## Eixo Tecnologia

Para o eixo de **Tecnologias** em Ciência de Dados, dividi o processo em marcos relevantes para um aprendizado progressivo, cobrindo desde habilidades fundamentais de manipulação de dados até MLOps para gerenciar e manter modelos em produção.

### **Marco 1: Fundamentos de Bancos de Dados e SQL**

**Objetivo:** Dominar SQL e bancos de dados relacionais, que são essenciais para a extração e manipulação de dados.

- **Fundamentos de SQL:**
    - Operações básicas de SQL (SELECT, INSERT, UPDATE, DELETE) para manipulação de dados.
    - Comandos avançados (JOINs, agrupamentos e subqueries) para análises mais complexas.
- **Modelagem e Estrutura de Dados:**
    - Entender como modelar e estruturar bancos de dados relacionais para otimizar a recuperação e organização dos dados.
- **Introdução a NoSQL:**
    - Introdução a bancos de dados NoSQL (como MongoDB) para armazenar e manipular dados não estruturados e semi-estruturados.

---

### **Marco 2: Fundamentos de Cloud Computing e Big Data**

**Objetivo:** Compreender os conceitos de cloud computing e Big Data, além de aprender a utilizar plataformas em nuvem para o armazenamento e processamento de grandes volumes de dados.

- **Fundamentos de Big Data:**
    - Conceitos e tecnologias de Big Data (como Hadoop e Spark) e suas aplicações para processar grandes volumes de dados.
- **Cloud Computing e Principais Provedores:**
    - Introdução aos conceitos de IaaS, PaaS e SaaS, e os principais provedores (AWS, Google Cloud, Azure).
    - Uso de ferramentas básicas para armazenamento (como Amazon S3) e processamento em cloud.
- **Configuração de Ambientes de Dados em Nuvem:**
    - Configuração de ambientes de trabalho em cloud, incluindo pipelines de dados e execução de tarefas em paralelo.

---

### **Marco 3: Controle de Versão e Git**

**Objetivo:** Aprender o uso de Git e GitHub para controle de versão, colaborando eficientemente com equipes e gerenciando versões de projetos.

- **Git e Controle de Versão:**
    - Comandos básicos do Git (commit, push, pull) e criação de branches para controlar diferentes versões de projetos.
- **Colaboração em Projetos com GitHub:**
    - Trabalhar com repositórios remotos, clonar e fazer pull requests para colaborar com equipes de desenvolvimento.
- **Gerenciamento de Conflitos e Merge:**
    - Resolver conflitos em merge e realizar revisão de código para manter o histórico de mudanças organizadas.

---

### **Marco 4: Automação e MLOps**

**Objetivo:** Implementar práticas de MLOps para a automação, gestão e monitoramento de modelos em produção, assegurando a confiabilidade dos modelos no ambiente de produção.

- **Automação de Modelos de Machine Learning:**
    - Uso de pipelines para automação de processos de modelagem, desde a coleta até o deploy dos modelos.
- **Monitoramento e Manutenção de Modelos:**
    - Ferramentas para monitorar a performance dos modelos após o deploy e atualização conforme novos dados.
- **Gestão de Versionamento de Modelos e Dados:**
    - Práticas de versionamento de dados e modelos para assegurar a rastreabilidade e conformidade dos modelos implantados.

---

### **Marco 5: Inteligências Artificiais**

**Objetivo:** Aprender a utilizar ferramentas de inteligência artificial para acelerar processos de programação e ciência de dados, ganhando eficiência em tarefas como debugging, automação e análise de dados.

- **Fundamentos de IA Aplicada ao Desenvolvimento e Ciência de Dados:**
    - Compreender o funcionamento básico de IAs como assistentes de código (ex.: Copilot, ChatGPT) e suas limitações para definir quando é útil aplicá-las.
- **Automação e Suporte em Programação com IAs:**
    - Uso de IAs para gerar e depurar código automaticamente, interpretar e sugerir soluções para erros comuns, e refatorar código com boas práticas.
    - Técnicas para revisar código gerado por IAs e adaptar soluções conforme as necessidades do projeto.
- **IA para Análise e Exploração de Dados:**
    - Aplicação de IAs para análise exploratória e visualização de dados, criando gráficos e relatórios rápidos para entendimento inicial dos dados.
    - Utilização de ferramentas de IA para pré-processamento e tratamento de dados (ex.: limpeza, identificação de outliers).
- **Automação de Processos Repetitivos com IAs:**
    - Implementação de IAs para automação de tarefas repetitivas, como a criação de templates de código, preparação de relatórios e análise de dados recorrentes.
    - Exploração de ferramentas para integração entre IAs e ambientes de programação (ex.: IDEs com integração a assistentes de código).

Este marco se concentra em integrar o uso de IAs no fluxo de trabalho de programação e ciência de dados, proporcionando maior eficiência e acelerando processos ao automatizar tarefas repetitivas e de suporte técnico.

---

Esses marcos oferecem uma base completa para trabalhar com infraestrutura e tecnologia aplicada a Ciência de Dados, suportando tanto o desenvolvimento quanto a implementação de soluções robustas e escaláveis.

### Tabela do Roadmap:

| **Marco** | **1. Fundamentos de Bancos de Dados e SQL** | **2. Fundamentos de Cloud Computing e Big Data** | **3. Controle de Versão e Git** | **4. Automação e MLOps** | **5. Inteligências Artificiais** |
| --- | --- | --- | --- | --- | --- |
| **Duração Estimada** | 1-1,5 meses | 2-3 meses | 1 mês | 2-3 meses | 1-1,5 meses |
| **Objetivo 1** | Conhecer as principais operações e comandos do SQL | Aprender os conceitos e tecnologias de Big Data, como Hadoop e Spark | Aprender comandos básicos do Git | Usar pipelines para automatizar Modelos de Machine Learning | Conhecer os fundamentos da IA Generativa como assistentes de código. |
| **Objetivo 2** | Dominar a modelagem e a estrutura de bancos de dados relacionais | Conhecer sobre IaaS, PaaS e SaaS e usar ferramentas (como Amazon S3) e provedores (AWS, Google Cloud, Azure) | Ser capaz de trabalhar com repositórios remotos | Dominar ferramentas para o monitoramento e manutenção de Modelos | Usar IA para gerar e depurar códigos automaticamente. |
| **Objetivo 3** | Conhecer bancos NoSQL, como o MongoDB | Configurar de Ambientes de Dados em Nuvem, como pipelines de dados e execução de tarefas em paralelo. | Resolver conflitos em merge e realizar revisão de código | Dominar práticas de versionamento de Modelos e Dados | Usar IA para análise e visualização de dados, pré-processamento e tratamento de dados. |
| **Objetivo 4** |  |  |  |  | Automatizar tarefas repetitivas com IA, como preparação de relatórios e análises. |

## Agenda semanal de estudos

Aqui está uma sugestão de agenda semanal organizada de forma a garantir que você estude 6 horas de segunda a sexta, com sessões de estudo intercaladas por dia e blocos de no mínimo 3 horas.

---

### **Agenda de Estudos Semanal**

| Dia | Manhã (4 horas) | Tarde (2 horas) |
| --- | --- | --- |
| **Segunda** | Data Science (Teoria) | Negócios |
| **Terça** | Data Science (Prática) | Tecnologia (Teoria) |
| **Quarta** | Data Science (Teoria) | Negócios |
| **Quinta** | Data Science (Prática) | Tecnologia (Teoria) |
| **Sexta** | Tecnologia (Prática) | Negócios |
| **Sábado** | Data Science (Revisão e Exercícios Práticos) - 4 horas | — |

---

### **Explicação da Estrutura**

1. **Data Science (20 horas semanais)**:
    - Estudado em todas as manhãs e tardes de segunda a quinta-feira, e na manhã de sábado, totalizando 5 sessões.
    - Intercalando teoria e prática para reforçar o aprendizado contínuo, com prática intensiva às tardes e uma revisão semanal no sábado.
2. **Negócios (6 horas semanais)**:
    - Distribuído em três sessões, segunda, quarta e sexta, em blocos de 2 horas.
    - Essa divisão garante que o conteúdo seja estudado de forma intercalada e assimilado entre uma sessão e outra.
3. **Tecnologia (8 horas semanais)**:
    - Estudado na manhã de sexta e nas tardes de terça e quinta-feira, com teoria e prática intercaladas, totalizando 8 horas.
    - Essa organização garante que você tenha dias de intervalo entre as sessões de tecnologia para reforçar a internalização do conteúdo.

Essa agenda mantém o equilíbrio entre teoria e prática em todos os eixos e permite que você aproveite o domingo para descanso, essencial para consolidar o conhecimento e recuperar energias para a semana seguinte.
